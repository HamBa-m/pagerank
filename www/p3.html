<!DOCTYPE html>
<html>
<head>
	<title>Double Q-learning with Prioritized Experience Replay</title>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
	<main>
		<h2>Double Q-learning with Prioritized Experience Replay</h2>
		<p>Abstract: Q-learning can be susceptible to overestimation of Q-values, which can lead to suboptimal policies. This paper proposes a modification to the standard Q-learning algorithm, called Double Q-learning, which reduces the overestimation bias. We also introduce Prioritized Experience Replay, a method for selecting experiences to replay during the learning process that further improves the performance of Double Q-learning.</p>
		<ul>
			<li><a href="p1.html">Q-Learning: Foundations, Algorithms, and Applications</a></li>
		</ul>
	</main>
	<footer>
		<p>&copy; 2023 Moroccan Mathematical Community - PageRank Demo</p>
	</footer>
</body>
</html>
